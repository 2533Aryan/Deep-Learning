{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyORHiEtWCwL8ur4jIyDvsfJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Lab Assignment 4: Neural Networks**\n","\n","This assignment is about building neural networks in Python. You will be introduced to the PyTorch library which is commonly used in Python coding for machine learning.\n","\n","**Remember to follow the principles of the rubric we developed:**\n","\n","1. Clarity/Comments\n","2. Accuracy\n","3. Typos\n","4. Grammar/Syntax\n","\n","**Possible Resources:**\n","\n","https://www.tensorflow.org/guide/tensor\n","\n","https://towardsdatascience.com/complete-guide-to-adam-optimization-1e5f29532c3d\n","https://machinelearningmastery.com/\n","\n","adam-optimization-algorithm-for-deep-learning/\n","\n","https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n","\n","\n"],"metadata":{"id":"YMVKLoLGb0qT"}},{"cell_type":"code","source":["# Import the following packages:\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable"],"metadata":{"id":"aOpZ7RP0dSvT","executionInfo":{"status":"ok","timestamp":1697509642768,"user_tz":240,"elapsed":6131,"user":{"displayName":"Abi Bowering","userId":"08482982247955201463"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["1.) Our goal is to build a neural network which, when trained, will represent an approximation of sin(x) from a sample of N equidistant points between x=0 and x=pi/2, and examine how various changes will affect the accuracy of the network."],"metadata":{"id":"4pO7tHcBclc-"}},{"cell_type":"markdown","source":["a). Generate the N equidistant points in the sin function between 0 and pi/2.\n"],"metadata":{"id":"UkXB2VaQdMai"}},{"cell_type":"code","source":["# Define N =\n","# Generate the points using x = np.linspace()\n","# Map the sine function from the generated x points using y = np.sin(x)\n","\n","# Graph the points using:\n","# plt.figure()\n","# plt.scatter(x,y)"],"metadata":{"id":"zj9PG7JCdji2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["b). Reshape the data from a NumPy array into a PyTorch Tensor to prep it for the network.\n"],"metadata":{"id":"sGANhFVeeN5Q"}},{"cell_type":"code","source":["# Eg: x = torch.from_numpy(x.reshape(-1, 1)).float()\n","\n","# torch.from_numpy() converts the reshaped NumPy array x into a PyTorch tensor.\n","# This is useful for working with neural networks because PyTorch tensors are used as the primary data structure for computations in PyTorch.\n","\n","#the reshape.(-1, 1) reshapes the x np array into a 2D array where there is only one column\n","# -1 signals that the shape is computed based on the number of rows\n","\n","#.float() converts the PyTorch tensor into a float datatype, the most common for network calculations"],"metadata":{"id":"ZCUymrMEehLY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["c). Define the network architecture, starting with two layers and width 10."],"metadata":{"id":"_wKCPXOGc932"}},{"cell_type":"code","source":["class Net(nn.Module):\n","    # def __init__(self):\n","    #     super(Net, self).__init__()\n","    #     self.layer1 = torch.nn.Linear()\n","    #     self.layer2 = torch.nn.Linear()\n","    #     self.activation = torch.nn.Tanh()\n","\n","    # def forward(self, x):\n","    #     x = self.layer1(x)\n","    #     x = self.activation(x)\n","    #     x = self.layer2(x)\n","    #     return x\n","\n","net = Net()\n","print(net)"],"metadata":{"id":"vnTQzjcpb3-2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["d). Define the optimizer and loss function. Start with 1000 epochs"],"metadata":{"id":"W-fuEDuSfdqh"}},{"cell_type":"code","source":["optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n","loss_func = torch.nn.MSELoss()\n","\n","#training\n","inputs = x\n","outputs = y\n","for i in range( # of epochs ):\n","    prediction = net(inputs)\n","    loss = loss_func(prediction, outputs)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    if i % 100==0:\n","        print('epoch', i, 'loss',loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"RqHo2EbVfeCo","executionInfo":{"status":"error","timestamp":1697511459345,"user_tz":240,"elapsed":9,"user":{"displayName":"Abi Bowering","userId":"08482982247955201463"}},"outputId":"b7d22342-7b10-4660-92b2-c4588c2d6041"},"execution_count":2,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-1d5479632930>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    for i in range( # of epochs ):\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"]}]},{"cell_type":"markdown","source":["e). Plot predicted and true functions\n"],"metadata":{"id":"82guxsbWgghN"}},{"cell_type":"code","source":["#plot predicted and true functions\n","plt.plot(x.detach().numpy(),outputs.detach().numpy(), label = 'True')\n","plt.plot(x.detach().numpy(),net(inputs).detach().numpy(), label = 'Predicted')\n","plt.legend()"],"metadata":{"id":"-2pzvtscgf2L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Repeat steps a). through e)., but change N so that N=4, 8, 16, 32, 100.\n","\n"],"metadata":{"id":"9T8XJOIyhIYS"}},{"cell_type":"code","source":[],"metadata":{"id":"4nbI7XCekq4t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Keeping N= 100, change the network to have 10, and then 20 layers. Continue printing the loss function every 100 epochs. How does the network training change? Write a few sentences about what you notice."],"metadata":{"id":"D1WSeaYBj_FA"}},{"cell_type":"code","source":[],"metadata":{"id":"7u_lNxlXj-Rs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Keeping N=100 and using 10 layers, alter the activation function of the network. Try instead of Tanh, the Sigmoid, ReLu, and Leaky ReLu activation functions. Continue printing the loss function every 100 epochs. How does the network training change? Write a few sentences about what you notice.\n","\n"],"metadata":{"id":"LZogFLZnkrpl"}},{"cell_type":"code","source":[],"metadata":{"id":"4A2kg4kDle-u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Keeping N=100 and using 10 layers, and the Tanh activation function, play with changing the learning rate of the network. Continue printing the loss function every 100 epochs. How does the network training change? Write a few sentences about what you notice.\n"],"metadata":{"id":"F2jYKUSSlU4p"}},{"cell_type":"code","source":[],"metadata":{"id":"f_i_sSsElTna"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Keeping N=100 and using 10 layers, and the Tanh, change the width of each layer. Try width=5 and width=10. Continue printing the loss function every 100 epochs. How does the network training change? Write a few sentences about what you notice.\n"],"metadata":{"id":"tRjTL7lDlfri"}},{"cell_type":"code","source":[],"metadata":{"id":"l--6ZFBbltTr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Bonus question: Repeat the first problem with N=100 and 10 layers, but instead of reconstructing the sine function, import a sound wave through Librosa, sample it and then reconstruct the sound from the samples through a network.**\n","\n","https://librosa.org/doc/latest/index.html\n","\n","Alter the activation function, learning rate, and and width. Notice changes in training speed and accuracy.\n"],"metadata":{"id":"79dFi2cMlwoJ"}},{"cell_type":"code","source":["pip install librosa\n","import librosa\n","\n","# audio_file =\n","\n","# y, sr = librosa.load(audio_file)"],"metadata":{"id":"_6AXkgPQlt3T"},"execution_count":null,"outputs":[]}]}